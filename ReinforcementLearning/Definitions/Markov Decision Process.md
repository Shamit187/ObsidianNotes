Sequential Decision Making
Action can influence:
- immediate rewards
- subsequent situations/state -> subsequent rewards
MDP estimates 
- $q_*(s,a)$ 
- $v_*(s)$ given optimal action selected
MDP is `Idealized form of Reinforcement Learning Problem` 
MDP must always have an [[Agent-Environment Interaction]]
MDP assumes [[Markov Property]] in States
To ensure the best result in MDP, make sure to follow [[Reward Hypothesis]]
